# LLM Benchmark Report

Latest source file: `benchmark_results_2025-08-31_14-33-31.csv`

## Model Performance Summary

| Model | Commit Similarity (avg) | Eisenhower Accuracy (avg) | Eisenhower Precision (avg) | Sprint Valid % | Avg Time (s) |
|-------|--------------------------|----------------------------|-----------------------------|----------------|-------------|
| TinyLlama | 0.0 | 0.362 | 0.0 | 100.0% | 0.059 |
| Deepseek | 0.0 | 0.362 | 0.0 | 100.0% | 0.065 |

## Performance Charts

### Commit Similarity
```mermaid
bar
title Commit Similarity
TinyLlama : 0.0
Deepseek : 0.0
```

### Eisenhower Accuracy
```mermaid
bar
title Eisenhower Accuracy
TinyLlama : 0.362
Deepseek : 0.362
```

### Eisenhower Precision
```mermaid
bar
title Eisenhower Precision
TinyLlama : 0.0
Deepseek : 0.0
```

### Sprint Planning Validity (%)
```mermaid
bar
title Sprint Valid %
TinyLlama : 100.0
Deepseek : 100.0
```

### Average Inference Time (s)
```mermaid
bar
title Avg Time per Prompt (s)
TinyLlama : 0.059
Deepseek : 0.065
```