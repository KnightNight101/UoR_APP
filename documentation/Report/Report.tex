\documentclass{report}
% Packages
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{csquotes}
\usepackage[style=authoryear-ibid,backend=biber]{biblatex}
\addbibresource{UoR_Masters_Project.biblatex}

% Page settings
\geometry{margin=1in}
\setlength{\parskip}{0.8em}
\setlength{\parindent}{0pt}
\doublespacing% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{ML-Powered Agile PM App}

% Title
\title{\textbf{An LLM-Powered Application for Agile Project Management}}
\author{Nithin Gandhi Simanand \\ Supervisor: Pat Parslow \\ MSc Data Science and Advanced Computing}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

% 1. Introduction
\chapter{Introduction}  % ~800 words
\section{Problem Statement and Motivation}

Enterprise-scale organisations routinely operate across a complex matrix of interdependent projects, distributed teams, and extensive resource portfolios. To maintain operational coherence and deliver value efficiently, these firms typically rely on structured project management frameworks such as PRINCE2, PMBOK, or Agile-based hybrids. While such methodologies have demonstrated clear benefits in improving project visibility, governance, and stakeholder alignment, they remain susceptible to inherent inefficiencies. These stem largely from the rigidities of hierarchical communication, bureaucratic inertia, and the sheer scale of coordination required in large corporate environments.

Despite adherence to best practices, many firms continue to experience avoidable project delays, resource misallocations, and suboptimal decision-making cycles \parencite{mankinsTurningGreatStrategy}. A significant portion of these inefficiencies can be traced to human limitations in managing high-dimensional data, repetitive administrative tasks, and the cognitive overload associated with large-scale project orchestration. This presents a critical bottleneck: even with mature frameworks in place, enterprise project management often lacks the real-time adaptability and computational agility required to fully optimize performance at scale.

The emergence of Large Language Models (LLMs) and Machine Learning (ML) systems offers a transformative opportunity to address these structural inefficiencies. These technologies excel at pattern recognition, predictive analysis, and automating low-level cognitive functions, all attributes that align closely with the pain points of modern project management. By offloading repetitive, computation-heavy, and data-intensive components of project workflows to intelligent systems, organizations can enable human stakeholders to concentrate on strategic, creative, and high-context tasks where human judgment is irreplaceable.

However, due to the ever-growing importance of data protection, firms are increasingly hesitant to integrate cloud-based AI providers into their workflows. Concerns surrounding the ambiguity of how data is processed, where it is transmitted, and which datasets were used to train these models have created a significant barrier to adoption. While some organizations attempt to mitigate this risk by deploying locally hosted LLMs, these models typically function as open-ended chatbots. Consequently, the quality and relevance of their outputs are highly dependent on the user's ability to craft precise, context-aware prompts. Given the diversity in LLM interfaces, capabilities, and task specialization, employees without training in prompt engineering or a deep understanding of model behavior often struggle to extract meaningful value — effectively neutralizing the potential gains these tools could offer.

This research is motivated by the need to bridge the gap between the theoretical capabilities of intelligent automation and their practical usability in real-world enterprise settings. The core problem lies not only in technical implementation, but also in aligning these systems with organizational workflows, ensuring security and compliance, and designing interfaces and processes that make advanced tools accessible to non-expert users. The goal is to explore how LLM- and ML-driven solutions can be securely, effectively, and intuitively integrated into large-scale project environments — enabling genuine improvements in efficiency, responsiveness, and decision quality without compromising data integrity or overwhelming the workforce.


\section{Project Objectives}

There are four main objectives for this project:
\subsection{Develop a Multi-Dimensional Sprint Planner}
The first goal is to design an intelligent sprint planning system that automates the prioritization and scheduling of project tasks. This planner considers multiple dynamic inputs, including team member availability, skill sets, task dependencies, organizational constraints, and regulatory and compliance related deadlines. The system is built to continuously ingest real-time updates, allowing it to refine project roadmaps dynamically as requirements shift. By embedding adaptive logic into the planner, the tool ensures that large-scale delivery remains aligned with strategic goals and operational timelines.
\subsection{Implement an Eisenhower Matrix-Based To-Do List Generator}
To enhance daily execution at the individual level, the system generates personalized task lists using the Eisenhower Matrix framework. This model categorizes tasks based on urgency and importance, helping users focus on high-impact work while deferring or delegating less critical activities. These lists are continuously updated based on project context and user input, supporting focused, high-leverage productivity without manual task sorting.
\subsection{Integrate a Version Control System with LLM-Generated Commit Summaries}
The third objective is to ensure knowledge continuity and reduce the cognitive cost of context switching by embedding a version control system (VCS) into the platform. The VCS tracks project artifacts, decisions, and revisions, while an LLM generates automatic commit summaries that document key changes in clear, concise language. These summaries can be aggregated into progress reports, streamlining communication with internal stakeholders and external clients. Additionally, the system surfaces relevant historical context during task transitions, reducing ramp-up time and minimizing productivity losses across team handovers or project shifts.
\subsection{Ensure Secure, Containerized Local Deployment}
Finally, the project emphasizes data security and deployment flexibility by containerizing the entire application for on-premise use. This architecture ensures that all data processing occurs within the organization’s infrastructure, mitigating the risks associated with cloud-based AI platforms. The modular software design also supports plug-and-play integration of different LLMs for specialized tasks, allowing components to be updated independently without disrupting the user experience. By abstracting LLM interactions behind clearly defined workflows, the system eliminates the need for prompt engineering, making advanced AI capabilities accessible to non-technical users.

Testing for this project will focus on validating both functional performance and usability across the four core components. For the multi-dimensional sprint planner, tests will assess the accuracy and adaptability of task prioritization and scheduling in response to simulated changes in team availability, task dependencies, and deadlines. The Eisenhower Matrix task generator will be evaluated on its ability to categorize tasks correctly based on urgency and importance, as well as its impact on user focus and task completion rates.
The version control system and commit summarization feature will be tested for robustness in tracking file changes, accuracy of LLM-generated summaries, and their usefulness in aiding project recall and progress reporting. Context-switching support will be assessed through user testing to measure reductions in ramp-up time when switching between tasks or projects.
Finally, the containerized deployment will be tested for security, performance, and reliability in an isolated enterprise environment. This includes ensuring data remains local, validating LLM module swap-ins do not disrupt functionality, and confirming that all features work without requiring prompt engineering. Across all components, user feedback will be collected to evaluate usability, clarity, and relevance—ensuring the system meets real-world enterprise expectations.

% 2. Background & Literature Review
\chapter{Background and Literature Review}  % ~2000 words


% 3. Methodology
\chapter{Methodology}  % ~1500 words
\section{Requirements Gathering}
\section{Design Methodology}
\section{Data Sources and Preprocessing}
\section{LLM Selection and Integration Strategy}
\section{System Architecture Overview}

% 4. System Design & Implementation
\chapter{System Design and Implementation}  % ~2000 words
\section{System Architecture}
\section{Frontend and Backend Design}
\section{Key Features and Functionalities}
\section{LLM Integration and Prompt Engineering}
\section{Security and Ethical Considerations}

% 5. Evaluation & Testing
\chapter{Evaluation and Testing}  % ~1500 words
\section{Evaluation Criteria}
\section{Functional Testing}
\section{LLM Response Evaluation}
\section{User Testing and Feedback}
\section{Limitations in Testing}

% 6. Discussion
\chapter{Discussion}  % ~1000 words
\section{Analysis of Results}
\section{Challenges Faced}
\section{Agile Methodology Reflection}
\section{Model Performance vs Expectations}

% 7. Conclusion & Future Work
\chapter{Conclusion and Future Work}  % ~700 words
\section{Summary of Contributions}
\section{Applications and Impact}
\section{Limitations}
\section{Future Improvements}

% References

\printbibliography% \bibliographystyle{plainnat}

% Appendices (not included in word count)
\appendix
\chapter{Screenshots and Interface Designs}
\chapter{Test Logs and Scripts}
\chapter{User Feedback and Survey Responses}



\end{document}
