\documentclass[12pt,a4paper]{report}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{setspace}

% Page settings
\geometry{margin=1in}
\setlength{\parskip}{0.8em}
\setlength{\parindent}{0pt}
%\doublespacing 

% Header and Footer
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{ML-Powered Agile PM App}

% Title
\title{\textbf{An LLM-Powered Application for Agile Project Management}}
\author{Nithin Gandhi Simanand \\ Supervisor: Pat Parslow \\ MSc Data Science and Advanced Computing}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

% 1. Introduction
\chapter{Introduction}  % ~800 words
\section{Problem Statement and Motivation}
Enterprise-scale organisations routinely operate across a complex matrix of interdependent projects, distributed teams, and extensive resource portfolios. To maintain operational coherence and deliver value efficiently, these firms typically rely on structured project management frameworks such as PRINCE2, PMBOK, or Agile-based hybrids. While such methodologies have demonstrated clear benefits in improving project visibility, governance, and stakeholder alignment, they remain susceptible to inherent inefficiencies. These stem largely from the rigidities of hierarchical communication, bureaucratic inertia, and the sheer scale of coordination required in large corporate environments.

Despite adherence to best practices, many firms continue to experience avoidable project delays, resource misallocations, and suboptimal decision-making cycles. A significant portion of these inefficiencies can be traced to human limitations in managing high-dimensional data, repetitive administrative tasks, and the cognitive overload associated with large-scale project orchestration. This presents a critical bottleneck: even with mature frameworks in place, enterprise project management often lacks the real-time adaptability and computational agility required to fully optimize performance at scale.

The emergence of Large Language Models (LLMs) and Machine Learning (ML) systems offers a transformative opportunity to address these structural inefficiencies. These technologies excel at pattern recognition, predictive analysis, and automating low-level cognitive functions, all attributes that align closely with the pain points of modern project management. By offloading repetitive, computation-heavy, and data-intensive components of project workflows to intelligent systems, organizations can enable human stakeholders to concentrate on strategic, creative, and high-context tasks where human judgment is irreplaceable.

However, due to the ever-growing importance of data protection, firms are increasingly hesitant to integrate cloud-based AI providers into their workflows. Concerns surrounding the ambiguity of how data is processed, where it is transmitted, and which datasets were used to train these models have created a significant barrier to adoption. While some organizations attempt to mitigate this risk by deploying locally hosted LLMs, these models typically function as open-ended chatbots. Consequently, the quality and relevance of their outputs are highly dependent on the user's ability to craft precise, context-aware prompts. Given the diversity in LLM interfaces, capabilities, and task specialization, employees without training in prompt engineering or a deep understanding of model behavior often struggle to extract meaningful value — effectively neutralizing the potential gains these tools could offer.

This research is motivated by the need to bridge the gap between the theoretical capabilities of intelligent automation and their practical usability in real-world enterprise settings. The core problem lies not only in technical implementation, but also in aligning these systems with organizational workflows, ensuring security and compliance, and designing interfaces and processes that make advanced tools accessible to non-expert users. The goal is to explore how LLM- and ML-driven solutions can be securely, effectively, and intuitively integrated into large-scale project environments — enabling genuine improvements in efficiency, responsiveness, and decision quality without compromising data integrity or overwhelming the workforce.


\section{Project Objectives}
The overarching aim of this project is to design and implement a secure, intelligent, and modular project management assistant that addresses key inefficiencies faced. The system is containerised for local deployment, ensuring that all data processing remains within company boundaries, which is critical given the growing concerns around data privacy, model transparency, and the use of proprietary information in third-party cloud-based AI systems.

The software's modular architecture enables different (LLMs) to be allocated to different tasks. This decoupled design allows models to be replaced or updated without affecting the overall user experience, ensuring long-term adaptability as the performance landscape of available LLMs evolves. Critically, all interactions are encapsulated within predefined features and workflows, removing the need for prompt engineering expertise. Users engage with a clear, purpose-built interface rather than raw language models, allowing non-technical staff to fully leverage the software's capabilities.

Agile methodology underpins the project’s development cycle, with synthetic training data and built-in feedback loops enabling iterative refinement. The centerpiece of the system is a multi-dimensional sprint planner that automates task prioritization and scheduling by considering factors such as team member skills and availability, organizational capacity, task dependencies and regulatory deadlines, to name a few. Project roadmaps are continuously refined in response to real-time inputs, ensuring that delivery remains aligned with deadlines even as priorities shift or disruptions occur. To support individual productivity, the system also generates personalized daily task lists using the Eisenhower Matrix, balancing urgency and importance to promote focused execution.

To address the often-overlooked challenge of knowledge continuity and context switching, the software integrates a version control system and file manager. This ensures that key documents and decisions are never lost or fragmented across disparate tools. An embedded LLM automatically summarizes changes and generates “commit summaries,” providing clear, concise records of project evolution. These summaries can be compiled into automated progress reports for both internal teams and external stakeholders, reducing the need for time-consuming meetings and lengthy status emails.

Furthermore, the contextual data accumulated through version control and task tracking is leveraged to minimize productivity losses during task or project transitions. By surfacing relevant background information dynamically, the software reduces the cognitive overhead associated with context switching, enabling team members to move seamlessly between assignments without repeated ramp-up time.

Together, these objectives converge to create a robust, secure, and intelligent system that augments enterprise project management with AI-driven efficiency, transparency, and adaptability while maintaining strict control over organizational data.

% 2. Background & Literature Review
\chapter{Background and Literature Review}  % ~2000 words
\section{Agile Methodology: Overview and Key Concepts}
\section{Existing Project Management Tools}
\section{Applications of ML/LLMs in Project Management}
\section{LLM Technologies: GPT, BERT, and Others}
\section{Gaps in Current Research and Tools}

% 3. Methodology
\chapter{Methodology}  % ~1500 words
\section{Requirements Gathering}
\section{Design Methodology}
\section{Data Sources and Preprocessing}
\section{LLM Selection and Integration Strategy}
\section{System Architecture Overview}

% 4. System Design & Implementation
\chapter{System Design and Implementation}  % ~2000 words
\section{System Architecture}
\section{Frontend and Backend Design}
\section{Key Features and Functionalities}
\section{LLM Integration and Prompt Engineering}
\section{Security and Ethical Considerations}

% 5. Evaluation & Testing
\chapter{Evaluation and Testing}  % ~1500 words
\section{Evaluation Criteria}
\section{Functional Testing}
\section{LLM Response Evaluation}
\section{User Testing and Feedback}
\section{Limitations in Testing}

% 6. Discussion
\chapter{Discussion}  % ~1000 words
\section{Analysis of Results}
\section{Challenges Faced}
\section{Agile Methodology Reflection}
\section{Model Performance vs Expectations}

% 7. Conclusion & Future Work
\chapter{Conclusion and Future Work}  % ~700 words
\section{Summary of Contributions}
\section{Applications and Impact}
\section{Limitations}
\section{Future Improvements}

% Appendices (not included in word count)
\appendix
\chapter{Screenshots and Interface Designs}
\chapter{Test Logs and Scripts}
\chapter{User Feedback and Survey Responses}

% References
\bibliographystyle{IEEEtran} % Or change to your required style
\bibliography{references}  % Add your .bib file later

\end{document}
