# LLM Benchmark Report

## Model Performance Summary

| Model | Commit Accuracy | Eisenhower Accuracy | Sprint Accuracy | Avg Time (s) |
|-------|----------------|------------------|----------------|--------------|
| deepseek-r1:8b | 0.890 | 0.000 | 0.000 | 63.221 |
| tinyllama:1.1b | 0.200 | 1.000 | 1.000 | 8.621 |

## Model Benchmark Diagram
```mermaid
gantt
    title Model Task Execution Times
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 36.12s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 38.33s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 46.29s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 57.65s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 42.68s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 37.45s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 43.14s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 40.33s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 54.59s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 60.10s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 37.76s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 240.52s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 41.81s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 50.12s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 35.27s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 50.29s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 22.72s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 32.89s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 47.50s
    taskdeepseek-r1_8b_Commit_Summary :done, 0, 70.52s
```
